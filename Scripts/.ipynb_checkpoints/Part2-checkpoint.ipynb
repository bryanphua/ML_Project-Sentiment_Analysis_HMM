{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis System using HMM\n",
    "\n",
    "Hidden Markov Model (HMM) is a statistical Markov model in which the system being modeled is assumed to be a Markov process with unobserved (i.e. hidden) states.\n",
    "\n",
    "In class, we have learnt the definition of HMM and we will be using it in this system to estimate our emission and transmission parameters.\n",
    "\n",
    "In this project, x’s are the natural language words, and y’s are the tags (such as O, B-positive)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import relevant libraries\n",
    "\n",
    "NumPy is the fundamental package for scientific computing with Python.\n",
    "\n",
    "pandas is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming. We will be using it to handle our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process File Functions\n",
    "\n",
    "We write a function to process the file that we are given to a suitable format for data handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(filename):\n",
    "    f = open(filename,'r')\n",
    "    lines = f.readlines()\n",
    "    datas = []\n",
    "    \n",
    "    start = 0\n",
    "    for i in range(len(lines)):\n",
    "        if lines[i] == '\\n':\n",
    "            datas.append(lines[start:i])\n",
    "            start = i+1\n",
    "        lines[i] = lines[i].replace('\\n','')\n",
    "        lines[i] = tuple(lines[i].split(' '))\n",
    "        \n",
    "    # check formatting\n",
    "    for i in range(len(datas)):\n",
    "        for j in range(len(datas[i])):\n",
    "            #print datas[i][j]\n",
    "            assert len(datas[i][j])==2\n",
    "            \n",
    "    \n",
    "    for i in range(len(datas)):\n",
    "        data = datas[i]\n",
    "        x = [word[0] for word in data]\n",
    "        y = [word[1] for word in data]\n",
    "        datas[i] = [x,y]\n",
    "    \n",
    "    all_x = []\n",
    "    for i in range(len(datas)):\n",
    "        for j in range(len(datas[i][0])):\n",
    "            all_x.append(datas[i][0][j])\n",
    "    x_set = frozenset(all_x)\n",
    "    \n",
    "    all_y = []\n",
    "    for i in range(len(datas)):\n",
    "        for j in range(len(datas[i][0])):\n",
    "            all_y.append(datas[i][1][j])\n",
    "    y_set = frozenset(all_y)\n",
    "    \n",
    "    return dict(data=datas,x_set=x_set,y_set=y_set)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = get_data('EN/train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5 pts) - Write a function that estimates the emission parameters from the training set using MLE\n",
    "\n",
    "    (maximum likelihood estimation): e(x|y) = Count(y->x) / Count(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_emission_counts(data_dict):\n",
    "    \"\"\"\n",
    "    returns (DataFrame,Series) \n",
    "    an emission count (y->x) DataFrame and y count Series\n",
    "    \"\"\"\n",
    "    data = data_dict['data']\n",
    "    x_set = data_dict['x_set']\n",
    "    y_set = data_dict['y_set']\n",
    "    count_em_df = pd.DataFrame(np.zeros((len(x_set),len(y_set))),index=x_set,columns=y_set)\n",
    "    count_y = pd.Series(np.zeros(len(y_set)),index=y_set)\n",
    "\n",
    "    for instance in data:\n",
    "        x_vector,y_vector = instance\n",
    "        for i in range(len(x_vector)):\n",
    "            x,y = x_vector[i],y_vector[i]\n",
    "            count_em_df.loc[x,y]+=1\n",
    "            count_y[y]+=1\n",
    "    return count_em_df,count_y\n",
    "\n",
    "def get_emission_params(data_dict):\n",
    "    \"\"\"\n",
    "    returns DataFrame representing conditional probabilities P(y|x)\n",
    "    \"\"\"\n",
    "    count_em_df,count_y = get_emission_counts(data_dict)\n",
    "    return count_em_df/count_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I-negative</th>\n",
       "      <th>I-neutral</th>\n",
       "      <th>B-neutral</th>\n",
       "      <th>I-positive</th>\n",
       "      <th>B-positive</th>\n",
       "      <th>B-negative</th>\n",
       "      <th>O</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>porcini</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002618</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concerned</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>removed</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:D</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dom</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           I-negative  I-neutral  B-neutral  I-positive  B-positive  \\\n",
       "porcini           0.0        0.0        0.0    0.001647         0.0   \n",
       "concerned         0.0        0.0        0.0    0.000000         0.0   \n",
       "removed           0.0        0.0        0.0    0.000000         0.0   \n",
       ":D                0.0        0.0        0.0    0.000000         0.0   \n",
       "Dom               0.0        0.0        0.0    0.000000         0.0   \n",
       "\n",
       "           B-negative         O  \n",
       "porcini      0.002618  0.000000  \n",
       "concerned    0.000000  0.000041  \n",
       "removed      0.000000  0.000041  \n",
       ":D           0.000000  0.000041  \n",
       "Dom          0.000000  0.000041  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "em_df = get_emission_params(data_dict)\n",
    "em_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I-negative    1.0\n",
       "I-neutral     1.0\n",
       "B-neutral     1.0\n",
       "I-positive    1.0\n",
       "B-positive    1.0\n",
       "B-negative    1.0\n",
       "O             1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_df.sum(axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (10 pts) One problem with estimating the emission parameters is that some words that appear in the test set do not appear in the training set. One simple idea to handle this issue is as follows. First, replace those words that appear less than k times in the training set with a special token #UNK# before training. This leads to a “modified training set”. We then use such a modified training set to train our model.\n",
    "### During the testing phase, if the word does not appear in the “modified training set”, we replace that word with #UNK# as well.\n",
    "### Set k to 3, implement this fix into your function for computing the emission parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_modified_counts(data_dict,k):\n",
    "    count_em_df,count_y = get_emission_counts(data_dict)\n",
    "    \n",
    "    counts_x = count_em_df.sum(axis=1)\n",
    "    fail = counts_x[counts_x<k]\n",
    "\n",
    "    unk = count_em_df.loc[fail.index].sum(axis=0)\n",
    "    unk.name = '#UNK#'\n",
    "   \n",
    "    modified_df = count_em_df.append(unk)\n",
    "    modified_df = modified_df.drop(fail.index, axis=0) \n",
    "    \n",
    "    return modified_df,count_y\n",
    "\n",
    "\n",
    "def get_modified_emission_params(data_dict,k=3):\n",
    "    \"\"\"\n",
    "    returns DataFrame representing conditional probabilities P(y|x)\n",
    "    \"\"\"\n",
    "    count_em_df,count_y = get_modified_counts(data_dict,k)\n",
    "    return count_em_df/count_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I-negative    1.0\n",
       "I-neutral     1.0\n",
       "B-neutral     1.0\n",
       "I-positive    1.0\n",
       "B-positive    1.0\n",
       "B-negative    1.0\n",
       "O             1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_em_params = get_modified_emission_params(data_dict)\n",
    "modified_em_params.sum(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I-negative</th>\n",
       "      <th>I-neutral</th>\n",
       "      <th>B-neutral</th>\n",
       "      <th>I-positive</th>\n",
       "      <th>B-positive</th>\n",
       "      <th>B-negative</th>\n",
       "      <th>O</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>they're</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waiting</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#UNK#</th>\n",
       "      <td>0.255639</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.169231</td>\n",
       "      <td>0.347611</td>\n",
       "      <td>0.242550</td>\n",
       "      <td>0.183246</td>\n",
       "      <td>0.116492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         I-negative  I-neutral  B-neutral  I-positive  B-positive  B-negative  \\\n",
       "t          0.000000   0.000000   0.000000    0.000000    0.000000    0.000000   \n",
       "they're    0.000000   0.000000   0.000000    0.000000    0.000000    0.000000   \n",
       "from       0.000000   0.000000   0.000000    0.000000    0.000000    0.000000   \n",
       "waiting    0.000000   0.000000   0.000000    0.000000    0.000828    0.000000   \n",
       "#UNK#      0.255639   0.217391   0.169231    0.347611    0.242550    0.183246   \n",
       "\n",
       "                O  \n",
       "t        0.000330  \n",
       "they're  0.000124  \n",
       "from     0.002063  \n",
       "waiting  0.000371  \n",
       "#UNK#    0.116492  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_em_params.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I-negative</th>\n",
       "      <th>I-neutral</th>\n",
       "      <th>B-neutral</th>\n",
       "      <th>I-positive</th>\n",
       "      <th>B-positive</th>\n",
       "      <th>B-negative</th>\n",
       "      <th>O</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>four</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NYC</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      I-negative  I-neutral  B-neutral  I-positive  B-positive  B-negative  \\\n",
       "four         0.0   0.000000        0.0         0.0    0.000828         0.0   \n",
       "NYC          0.0   0.043478        0.0         0.0    0.000000         0.0   \n",
       "\n",
       "             O  \n",
       "four  0.000248  \n",
       "NYC   0.000578  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_df.loc[['four','NYC']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (10 pts) Implement a simple sentiment analysis system that produces the tag\n",
    "```y* = argmax_y e(x|y) ```\n",
    "### for each word x in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(filename,k=3):\n",
    "    data_dict = get_data(filename)\n",
    "    return get_modified_emission_params(data_dict,k=k)\n",
    "\n",
    "def argmax_y(emission_params,x):\n",
    "    # check if x in trained x's \n",
    "    if x not in emission_params.index:\n",
    "        x = '#UNK#'\n",
    "    p = emission_params.loc[x,:]\n",
    "    \n",
    "    max_p = None\n",
    "    for col in p.index:\n",
    "        if max_p is None:\n",
    "            max_p = p.loc[col]\n",
    "            y = col\n",
    "        elif p.loc[col]>max_p:\n",
    "            max_p = p.loc[col]\n",
    "            y = col\n",
    "    return y\n",
    "\n",
    "def decode(filename,emission_params,outfile):\n",
    "    f = open(filename,'r')\n",
    "    lines = f.readlines()\n",
    "    lines = [line.replace('\\n','') for line in lines]\n",
    "    #print lines\n",
    "    \n",
    "    for i in range(len(lines)):\n",
    "        line = lines[i]\n",
    "        if line != '':\n",
    "            line = line +' '+argmax_y(emission_params,line)\n",
    "        line += '\\n'\n",
    "        \n",
    "        lines[i] = line\n",
    "        \n",
    "    fout = open(outfile,'w')\n",
    "    for line in lines:\n",
    "        fout.write(line)\n",
    "    fout.close()\n",
    "    print(\"decoding completed\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-negative    0.000000\n",
      "I-neutral     0.043478\n",
      "B-neutral     0.000000\n",
      "I-positive    0.000000\n",
      "B-positive    0.000000\n",
      "B-negative    0.000000\n",
      "O             0.000578\n",
      "Name: NYC, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I-neutral'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'NYC'\n",
    "try:\n",
    "    print(modified_em_params.loc[word])\n",
    "except:\n",
    "    word = '#UNK#'\n",
    "    print(modified_em_params.loc[word])\n",
    "argmax_y(modified_em_params,word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Decoding on EN data Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoding completed\n"
     ]
    }
   ],
   "source": [
    "emission_params = train('EN/train')\n",
    "decode('EN/dev.in',emission_params,'EN/dev.p2.out')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    ">python3 evalResult.py EN/dev.out EN/dev.p2.out\n",
    "\n",
    "#Entity in gold data: 226\n",
    "#Entity in prediction: 1201\n",
    "\n",
    "#Correct Entity : 165\n",
    "Entity  precision: 0.1374\n",
    "Entity  recall: 0.7301\n",
    "Entity  F: 0.2313\n",
    "\n",
    "#Correct Sentiment : 71\n",
    "Sentiment  precision: 0.0591\n",
    "Sentiment  recall: 0.3142\n",
    "Sentiment  F: 0.0995\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Decoding on CN data Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x90 in position 22: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-204cdbd46988>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0memission_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'CN/train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'CN/dev.in'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0memission_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'CN/dev.p2.out'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-87a2d5417d33>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(filename, k)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdata_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mget_modified_emission_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0margmax_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memission_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-fd7c4c52249b>\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mdatas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\weiqu\\Anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x90 in position 22: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "emission_params = train('CN/train')\n",
    "decode('CN/dev.in',emission_params,'CN/dev.p2.out')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    ">python3 evalResult.py CN/dev.out CN/dev.p2.out\n",
    "\n",
    "#Entity in gold data: 362\n",
    "#Entity in prediction: 3318\n",
    "\n",
    "#Correct Entity : 183\n",
    "Entity  precision: 0.0552\n",
    "Entity  recall: 0.5055\n",
    "Entity  F: 0.0995\n",
    "\n",
    "#Correct Sentiment : 57\n",
    "Sentiment  precision: 0.0172\n",
    "Sentiment  recall: 0.1575\n",
    "Sentiment  F: 0.0310\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Decoding on FR data Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoding completed\n"
     ]
    }
   ],
   "source": [
    "emission_params = train('FR/train')\n",
    "decode('FR/dev.in',emission_params,'FR/dev.p2.out')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    ">python3 evalResult.py FR/dev.out FR/dev.p2.out\n",
    "\n",
    "#Entity in gold data: 223\n",
    "#Entity in prediction: 1149\n",
    "\n",
    "#Correct Entity : 182\n",
    "Entity  precision: 0.1584\n",
    "Entity  recall: 0.8161\n",
    "Entity  F: 0.2653\n",
    "\n",
    "#Correct Sentiment : 68\n",
    "Sentiment  precision: 0.0592\n",
    "Sentiment  recall: 0.3049\n",
    "Sentiment  F: 0.0991\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Decoding on SG data Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoding completed\n"
     ]
    }
   ],
   "source": [
    "emission_params = train('SG/train')\n",
    "decode('SG/dev.in',emission_params,'SG/dev.p2.out')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    ">python3 evalResult.py SG/dev.out SG/dev.p2.out\n",
    "\n",
    "#Entity in gold data: 1382\n",
    "#Entity in prediction: 6599\n",
    "\n",
    "#Correct Entity : 794\n",
    "Entity  precision: 0.1203\n",
    "Entity  recall: 0.5745\n",
    "Entity  F: 0.1990\n",
    "\n",
    "#Correct Sentiment : 315\n",
    "Sentiment  precision: 0.0477\n",
    "Sentiment  recall: 0.2279\n",
    "Sentiment  F: 0.0789\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "#Entity in gold data: 1382\r\n",
      "#Entity in prediction: 6599\r\n",
      "\r\n",
      "#Correct Entity : 794\r\n",
      "Entity  precision: 0.1203\r\n",
      "Entity  recall: 0.5745\r\n",
      "Entity  F: 0.1990\r\n",
      "\r\n",
      "#Correct Sentiment : 315\r\n",
      "Sentiment  precision: 0.0477\r\n",
      "Sentiment  recall: 0.2279\r\n",
      "Sentiment  F: 0.0789\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "p = subprocess.Popen(['python3','evalResult.py','SG/dev.out','SG/dev.p2.out'], stdout=subprocess.PIPE)\n",
    "print p.communicate()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
