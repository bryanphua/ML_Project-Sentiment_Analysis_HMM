{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (20 pts) Use the estimated transition and emission parameters, implement the alternative max-marginal decoding algorithm. Clearly describe the steps of your algorithm in your report.\n",
    "### Run the algorithm on the development sets EN/dev.in and FR/dev.in only. Write the outputs to EN/dev.p4.out and FR/dev.p4.out. Report the precision, recall and F scores for the outputs for both languages.\n",
    "### Hint: the max-marginal decoding involves the implementation of the forward-backward algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emission and Transition functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename):\n",
    "    f = open(filename,'r')\n",
    "    lines = f.readlines()\n",
    "    datas = []\n",
    "    \n",
    "    start = 0\n",
    "    for i in range(len(lines)):\n",
    "        if lines[i] == '\\n':\n",
    "            datas.append(lines[start:i])\n",
    "            start = i+1\n",
    "        lines[i] = lines[i].replace('\\n','')\n",
    "        lines[i] = tuple(lines[i].split(' '))\n",
    "        \n",
    "    # check formatting\n",
    "    for i in range(len(datas)):\n",
    "        for j in range(len(datas[i])):\n",
    "            #print datas[i][j]\n",
    "            assert len(datas[i][j])==2\n",
    "            \n",
    "    \n",
    "    for i in range(len(datas)):\n",
    "        data = datas[i]\n",
    "        x = [word[0] for word in data]\n",
    "        y = [word[1] for word in data]\n",
    "        datas[i] = [x,y]\n",
    "    \n",
    "    all_x = []\n",
    "    for i in range(len(datas)):\n",
    "        for j in range(len(datas[i][0])):\n",
    "            all_x.append(datas[i][0][j])\n",
    "    x_set = frozenset(all_x)\n",
    "    \n",
    "    all_y = []\n",
    "    for i in range(len(datas)):\n",
    "        for j in range(len(datas[i][0])):\n",
    "            all_y.append(datas[i][1][j])\n",
    "    y_set = frozenset(all_y)\n",
    "    \n",
    "    return dict(data=datas,x_set=x_set,y_set=y_set)\n",
    "\n",
    "def get_unlabelled_data(filename):\n",
    "    f = open(filename,'r')\n",
    "    lines = f.readlines()\n",
    "    datas = []\n",
    "    \n",
    "    start = 0\n",
    "    for i in range(len(lines)):\n",
    "        if lines[i] == '\\n':\n",
    "            datas.append(lines[start:i])\n",
    "            start = i+1\n",
    "        lines[i] = lines[i].replace('\\n','')\n",
    "            \n",
    "    return datas\n",
    "\n",
    "def get_transmission_params(data_dict):\n",
    "    from_y = ['START'] + list(data_dict['y_set']) \n",
    "    to_y = list(data_dict['y_set']) + ['STOP']\n",
    "    l = len(from_y)\n",
    "    transmission_count = pd.DataFrame(np.zeros((l,l)),index=from_y,columns=to_y)\n",
    "\n",
    "    datas = data_dict['data']\n",
    "    for instance in datas:\n",
    "        x_vector,y_vector = instance\n",
    "        length = len(y_vector)\n",
    "        for i in range(length+1):\n",
    "            if i == 0 :\n",
    "                transmission_count.loc['START',y_vector[0]] += 1\n",
    "\n",
    "            elif i == length:\n",
    "                transmission_count.loc[y_vector[i-1],'STOP'] +=1\n",
    "\n",
    "            else:\n",
    "                transmission_count.loc[y_vector[i-1],y_vector[i]] += 1\n",
    "\n",
    "    y_count = transmission_count.sum(axis=1) \n",
    "    transmission_params = transmission_count\n",
    "    for i in range(len(transmission_count.index)):\n",
    "        transmission_params.iloc[i,:] /= transmission_params.iloc[i,:].sum()\n",
    "    return transmission_params\n",
    "\n",
    "def get_emission_counts(data_dict):\n",
    "    \"\"\"\n",
    "    returns (DataFrame,Series) \n",
    "    an emission count (y->x) DataFrame and y count Series\n",
    "    \"\"\"\n",
    "    data = data_dict['data']\n",
    "    x_set = data_dict['x_set']\n",
    "    y_set = data_dict['y_set']\n",
    "    count_em_df = pd.DataFrame(np.zeros((len(x_set),len(y_set))),index=x_set,columns=y_set)\n",
    "    count_y = pd.Series(np.zeros(len(y_set)),index=y_set)\n",
    "\n",
    "    for instance in data:\n",
    "        x_vector,y_vector = instance\n",
    "        for i in range(len(x_vector)):\n",
    "            x,y = x_vector[i],y_vector[i]\n",
    "            count_em_df.loc[x,y]+=1\n",
    "            count_y[y]+=1\n",
    "    return count_em_df,count_y\n",
    "\n",
    "def get_modified_counts(data_dict,k):\n",
    "    count_em_df,count_y = get_emission_counts(data_dict)\n",
    "    \n",
    "    counts_x = count_em_df.sum(axis=1)\n",
    "    fail = counts_x[counts_x<k]\n",
    "\n",
    "    unk = count_em_df.loc[fail.index].sum(axis=0)\n",
    "    unk.name = '#UNK#'\n",
    "   \n",
    "    modified_df = count_em_df.append(unk)\n",
    "    modified_df = modified_df.drop(fail.index, axis=0) \n",
    "    \n",
    "    return modified_df,count_y\n",
    "\n",
    "\n",
    "def get_modified_emission_params(data_dict,k=3):\n",
    "    \"\"\"\n",
    "    returns DataFrame representing conditional probabilities P(y|x)\n",
    "    \"\"\"\n",
    "    count_em_df,count_y = get_modified_counts(data_dict,k)\n",
    "    return count_em_df/count_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Marginal Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forward_prob(x_vector,trans_params,em_params):\n",
    "    \n",
    "    states = trans_params.index.tolist()\n",
    "    states.remove('START')\n",
    "    states.remove('O')\n",
    "    states = ['O']+states\n",
    "\n",
    "    arr = np.zeros((len(states),len(x_vector))) *np.nan\n",
    "\n",
    "    alpha = pd.DataFrame(arr,index=states,columns=x_vector)\n",
    "\n",
    "    # base case\n",
    "    for i in range(len(states)):\n",
    "        alpha.iloc[i,0] = trans_params.loc['START',states[i]]\n",
    "    \n",
    "    # recursive case\n",
    "    for i in range(1,len(x_vector)):\n",
    "        for u in range(len(states)):\n",
    "            summ = 0\n",
    "            for v in range(len(states)):\n",
    "                summ += alpha.iloc[v,i-1] * trans_params.loc[states[v],states[u]] * \\\n",
    "                        em_params.loc[x_vector[i],states[v]]\n",
    "            alpha.loc[states[u],x_vector[i]] = summ\n",
    "    \n",
    "    return alpha\n",
    "\n",
    "def get_backward_prob(x_vector,trans_params,em_params):\n",
    "\n",
    "    states = trans_params.index.tolist()\n",
    "    states.remove('START')\n",
    "    states.remove('O')\n",
    "    states = ['O']+states\n",
    "\n",
    "    arr = np.zeros((len(states),len(x_vector))) *np.nan\n",
    "\n",
    "    beta = pd.DataFrame(arr,index=states,columns=x_vector)\n",
    "\n",
    "    # base case\n",
    "    for i in range(len(states)):\n",
    "        beta.iloc[i,len(x_vector)-1] = trans_params.loc[states[i],'STOP'] * \\\n",
    "                                       em_params.loc[x_vector[-1],states[i]]\n",
    "     \n",
    "    # recursive case\n",
    "    for i in range(len(x_vector)-2,-1,-1):\n",
    "        for u in range(len(states)):\n",
    "            summ = 0\n",
    "            for v in range(len(states)):\n",
    "                summ += beta.iloc[v,i+1] * trans_params.loc[states[u],states[v]] * \\\n",
    "                        em_params.loc[x_vector[i],states[u]]\n",
    "            beta.iloc[u,i] = summ\n",
    "    \n",
    "    return beta\n",
    "\n",
    "def max_marginal_decode(x_vector,trans_params,em_params):\n",
    "    \n",
    "    alpha = get_forward_prob(x_vector,trans_params,em_params)\n",
    "    beta = get_backward_prob(x_vector,trans_params,em_params)\n",
    "    \n",
    "    states = trans_params.index.tolist()\n",
    "    states.remove('START')\n",
    "    states.remove('O')\n",
    "    states = ['O']+states\n",
    "    \n",
    "    prediction_indx = []\n",
    "    \n",
    "    for i in range(len(x_vector)):\n",
    "        maxx = None\n",
    "        argmax = None\n",
    "        for u in range(len(states)):\n",
    "            prob = alpha.iloc[u,i] * beta.iloc[u,i]\n",
    "            if maxx is None:\n",
    "                maxx = prob\n",
    "                argmax = u\n",
    "            elif prob > maxx:\n",
    "                maxx = prob\n",
    "                argmax = u\n",
    "        prediction_indx.append(argmax)\n",
    "        \n",
    "    prediction = [states[indx] for indx in prediction_indx]\n",
    "    return prediction\n",
    "\n",
    "def decode_file(fin,fout,trans_params,em_params):\n",
    "    word_bag = em_params.index.tolist()\n",
    "    unlabelled_datas = get_unlabelled_data(fin)\n",
    "    \n",
    "    results = []\n",
    "    for obs_vector in unlabelled_datas:\n",
    "        copy = []\n",
    "        for i in range(len(obs_vector)):\n",
    "            if obs_vector[i] in word_bag:\n",
    "                copy.append(obs_vector[i])\n",
    "            else:\n",
    "                copy.append('#UNK#')\n",
    "        result = max_marginal_decode(copy,trans_params,em_params)\n",
    "        assert len(result) == len(obs_vector)\n",
    "        results.append(result)\n",
    "    \n",
    "    fout = file(fout,'w')\n",
    "    for i in range(len(unlabelled_datas)):\n",
    "        for j in range(len(unlabelled_datas[i])):\n",
    "            x = unlabelled_datas[i][j]\n",
    "            y = results[i][j]\n",
    "            fout.write('{} {}\\n'.format(x,y))\n",
    "        fout.write('\\n')\n",
    "    fout.close\n",
    "    print \"max marginal decoding complete\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Decoding on EN data Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ..\n",
      "decoding ..\n",
      "max marginal decoding complete\n"
     ]
    }
   ],
   "source": [
    "print 'training ..'\n",
    "data_dict = get_data('EN/train')\n",
    "trans_params = get_transmission_params(data_dict)\n",
    "em_params = get_modified_emission_params(data_dict,k=3)\n",
    "\n",
    "print 'decoding ..'\n",
    "decode_file('EN/dev.in','EN/dev.p4.out',trans_params,em_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    ">python3 evalResult.py EN/dev.out EN/dev.p4.out\n",
    "\n",
    "#Entity in gold data: 226\n",
    "#Entity in prediction: 180\n",
    "\n",
    "#Correct Entity : 94\n",
    "Entity  precision: 0.5222\n",
    "Entity  recall: 0.4159\n",
    "Entity  F: 0.4631\n",
    "\n",
    "#Correct Sentiment : 57\n",
    "Sentiment  precision: 0.3167\n",
    "Sentiment  recall: 0.2522\n",
    "Sentiment  F: 0.2808\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Decoding on FR data Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ..\n",
      "decoding ..\n",
      "max marginal decoding complete\n"
     ]
    }
   ],
   "source": [
    "print 'training ..'\n",
    "data_dict = get_data('FR/train')\n",
    "trans_params = get_transmission_params(data_dict)\n",
    "em_params = get_modified_emission_params(data_dict,k=3)\n",
    "\n",
    "print 'decoding ..'\n",
    "decode_file('FR/dev.in','FR/dev.p4.out',trans_params,em_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    ">python3 evalResult.py FR/dev.out FR/dev.p4.out\n",
    "\n",
    "#Entity in gold data: 223\n",
    "#Entity in prediction: 77\n",
    "\n",
    "#Correct Entity : 26\n",
    "Entity  precision: 0.3377\n",
    "Entity  recall: 0.1166\n",
    "Entity  F: 0.1733\n",
    "\n",
    "#Correct Sentiment : 11\n",
    "Sentiment  precision: 0.1429\n",
    "Sentiment  recall: 0.0493\n",
    "Sentiment  F: 0.0733\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
