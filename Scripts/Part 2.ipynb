{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process File Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename):\n",
    "    f = open(filename,'r')\n",
    "    lines = f.readlines()\n",
    "    datas = []\n",
    "    \n",
    "    start = 0\n",
    "    for i in range(len(lines)):\n",
    "        if lines[i] == '\\n':\n",
    "            datas.append(lines[start:i])\n",
    "            start = i+1\n",
    "        lines[i] = lines[i].replace('\\n','')\n",
    "        lines[i] = tuple(lines[i].split(' '))\n",
    "        \n",
    "    # check formatting\n",
    "    for i in range(len(datas)):\n",
    "        for j in range(len(datas[i])):\n",
    "            #print datas[i][j]\n",
    "            assert len(datas[i][j])==2\n",
    "            \n",
    "    \n",
    "    for i in range(len(datas)):\n",
    "        data = datas[i]\n",
    "        x = [word[0] for word in data]\n",
    "        y = [word[1] for word in data]\n",
    "        datas[i] = [x,y]\n",
    "    \n",
    "    all_x = []\n",
    "    for i in range(len(datas)):\n",
    "        for j in range(len(datas[i][0])):\n",
    "            all_x.append(datas[i][0][j])\n",
    "    x_set = frozenset(all_x)\n",
    "    \n",
    "    all_y = []\n",
    "    for i in range(len(datas)):\n",
    "        for j in range(len(datas[i][0])):\n",
    "            all_y.append(datas[i][1][j])\n",
    "    y_set = frozenset(all_y)\n",
    "    \n",
    "    return dict(data=datas,x_set=x_set,y_set=y_set)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = get_data('EN/train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Write a function that estimates the emission parameters from the training set using MLE\n",
    "(maximum likelihood estimation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emission_counts(data_dict):\n",
    "    \"\"\"\n",
    "    returns (DataFrame,Series) \n",
    "    an emission count (y->x) DataFrame and y count Series\n",
    "    \"\"\"\n",
    "    data = data_dict['data']\n",
    "    x_set = data_dict['x_set']\n",
    "    y_set = data_dict['y_set']\n",
    "    count_em_df = pd.DataFrame(np.zeros((len(x_set),len(y_set))),index=x_set,columns=y_set)\n",
    "    count_y = pd.Series(np.zeros(len(y_set)),index=y_set)\n",
    "\n",
    "    for instance in data:\n",
    "        x_vector,y_vector = instance\n",
    "        for i in range(len(x_vector)):\n",
    "            x,y = x_vector[i],y_vector[i]\n",
    "            count_em_df.loc[x,y]+=1\n",
    "            count_y[y]+=1\n",
    "    return count_em_df,count_y\n",
    "\n",
    "def get_emission_params(data_dict):\n",
    "    \"\"\"\n",
    "    returns DataFrame representing conditional probabilities P(y|x)\n",
    "    \"\"\"\n",
    "    count_em_df,count_y = get_emission_counts(data_dict)\n",
    "    return count_em_df/count_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B-neutral</th>\n",
       "      <th>B-positive</th>\n",
       "      <th>O</th>\n",
       "      <th>B-negative</th>\n",
       "      <th>I-neutral</th>\n",
       "      <th>I-positive</th>\n",
       "      <th>I-negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>limited</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>too--but</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unpretentious</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>four</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dining</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               B-neutral  B-positive         O  B-negative  I-neutral  \\\n",
       "limited              0.0    0.000000  0.000083         0.0        0.0   \n",
       "too--but             0.0    0.000000  0.000041         0.0        0.0   \n",
       "unpretentious        0.0    0.000000  0.000083         0.0        0.0   \n",
       "four                 0.0    0.000828  0.000248         0.0        0.0   \n",
       "Dining               0.0    0.000828  0.000000         0.0        0.0   \n",
       "\n",
       "               I-positive  I-negative  \n",
       "limited               0.0         0.0  \n",
       "too--but              0.0         0.0  \n",
       "unpretentious         0.0         0.0  \n",
       "four                  0.0         0.0  \n",
       "Dining                0.0         0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "em_df = get_emission_params(data_dict)\n",
    "em_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B-neutral     1.0\n",
       "B-positive    1.0\n",
       "O             1.0\n",
       "B-negative    1.0\n",
       "I-neutral     1.0\n",
       "I-positive    1.0\n",
       "I-negative    1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_df.sum(axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (10 pts) One problem with estimating the emission parameters is that some words that appear in the test set do not appear in the training set. One simple idea to handle this issue is as follows. First, replace those words that appear less than k times in the training set with a special token #UNK# before training. This leads to a “modified training set”. We then use such a modified training set to train our model.\n",
    "### During the testing phase, if the word does not appear in the “modified training set”, we replace that word with #UNK# as well.\n",
    "### Set k to 3, implement this fix into your function for computing the emission parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_modified_counts(data_dict,k):\n",
    "    count_em_df,count_y = get_emission_counts(data_dict)\n",
    "    \n",
    "    counts_x = count_em_df.sum(axis=1)\n",
    "    fail = counts_x[counts_x<k]\n",
    "\n",
    "    unk = count_em_df.loc[fail.index].sum(axis=0)\n",
    "    unk.name = '#UNK#'\n",
    "   \n",
    "    modified_df = count_em_df.append(unk)\n",
    "    modified_df = modified_df.drop(fail.index, axis=0) \n",
    "    \n",
    "    return modified_df,count_y\n",
    "\n",
    "\n",
    "def get_modified_emission_params(data_dict,k=3):\n",
    "    \"\"\"\n",
    "    returns DataFrame representing conditional probabilities P(y|x)\n",
    "    \"\"\"\n",
    "    count_em_df,count_y = get_modified_counts(data_dict,k)\n",
    "    return count_em_df/count_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B-neutral     1.0\n",
       "B-positive    1.0\n",
       "O             1.0\n",
       "B-negative    1.0\n",
       "I-neutral     1.0\n",
       "I-positive    1.0\n",
       "I-negative    1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_em_params = get_modified_emission_params(data_dict)\n",
    "modified_em_params.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B-neutral</th>\n",
       "      <th>B-positive</th>\n",
       "      <th>O</th>\n",
       "      <th>B-negative</th>\n",
       "      <th>I-neutral</th>\n",
       "      <th>I-positive</th>\n",
       "      <th>I-negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>–</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002393</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.003295</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>portion</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#UNK#</th>\n",
       "      <td>0.169231</td>\n",
       "      <td>0.242550</td>\n",
       "      <td>0.116492</td>\n",
       "      <td>0.183246</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.347611</td>\n",
       "      <td>0.255639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         B-neutral  B-positive         O  B-negative  I-neutral  I-positive  \\\n",
       "–         0.000000    0.000000  0.002393    0.000000   0.000000    0.000000   \n",
       "'         0.000000    0.000000  0.000660    0.000000   0.000000    0.000000   \n",
       "’         0.000000    0.000000  0.000578    0.000000   0.043478    0.003295   \n",
       "portion   0.000000    0.000828  0.000083    0.000000   0.000000    0.000000   \n",
       "#UNK#     0.169231    0.242550  0.116492    0.183246   0.217391    0.347611   \n",
       "\n",
       "         I-negative  \n",
       "–          0.000000  \n",
       "'          0.007519  \n",
       "’          0.000000  \n",
       "portion    0.000000  \n",
       "#UNK#      0.255639  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_em_params.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B-neutral</th>\n",
       "      <th>B-positive</th>\n",
       "      <th>O</th>\n",
       "      <th>B-negative</th>\n",
       "      <th>I-neutral</th>\n",
       "      <th>I-positive</th>\n",
       "      <th>I-negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>four</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NYC</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      B-neutral  B-positive         O  B-negative  I-neutral  I-positive  \\\n",
       "four        0.0    0.000828  0.000248         0.0   0.000000         0.0   \n",
       "NYC         0.0    0.000000  0.000578         0.0   0.043478         0.0   \n",
       "\n",
       "      I-negative  \n",
       "four         0.0  \n",
       "NYC          0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_df.loc[['four','NYC']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (10 pts) Implement a simple sentiment analysis system that produces the tag\n",
    "```y\u0003 = argmax_y e(x|y) ```\n",
    "### for each word x in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(filename,k=3):\n",
    "    data_dict = get_data(filename)\n",
    "    return get_modified_emission_params(data_dict,k=k)\n",
    "\n",
    "def argmax_y(emission_params,x):\n",
    "    # check if x in trained x's \n",
    "    if x not in emission_params.index:\n",
    "        x = '#UNK#'\n",
    "    p = emission_params.loc[x,:]\n",
    "    \n",
    "    max_p = None\n",
    "    for col in p.index:\n",
    "        if max_p is None:\n",
    "            max_p = p.loc[col]\n",
    "            y = col\n",
    "        elif p.loc[col]>max_p:\n",
    "            max_p = p.loc[col]\n",
    "            y = col\n",
    "    return y\n",
    "\n",
    "def decode(filename,emission_params,outfile):\n",
    "    f = open(filename,'r')\n",
    "    lines = f.readlines()\n",
    "    lines = [line.replace('\\n','') for line in lines]\n",
    "    #print lines\n",
    "    \n",
    "    for i in range(len(lines)):\n",
    "        line = lines[i]\n",
    "        if line != '':\n",
    "            line = line +' '+argmax_y(emission_params,line)\n",
    "        line += '\\n'\n",
    "        \n",
    "        lines[i] = line\n",
    "        \n",
    "    fout = open(outfile,'w')\n",
    "    for line in lines:\n",
    "        fout.write(line)\n",
    "    fout.close()\n",
    "    print \"decoding completed\"\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-neutral     0.000000\n",
      "B-positive    0.000000\n",
      "O             0.000578\n",
      "B-negative    0.000000\n",
      "I-neutral     0.043478\n",
      "I-positive    0.000000\n",
      "I-negative    0.000000\n",
      "Name: NYC, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I-neutral'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'NYC'\n",
    "try:\n",
    "    print modified_em_params.loc[word]\n",
    "except:\n",
    "    word = '#UNK#'\n",
    "    print modified_em_params.loc[word]\n",
    "argmax_y(modified_em_params,word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Decoding on EN data Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoding completed\n"
     ]
    }
   ],
   "source": [
    "emission_params = train('EN/train')\n",
    "decode('EN/dev.in',emission_params,'EN/dev.p2.out')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    ">python3 evalResult.py EN/dev.out EN/dev.p2.out\n",
    "\n",
    "#Entity in gold data: 226\n",
    "#Entity in prediction: 1201\n",
    "\n",
    "#Correct Entity : 165\n",
    "Entity  precision: 0.1374\n",
    "Entity  recall: 0.7301\n",
    "Entity  F: 0.2313\n",
    "\n",
    "#Correct Sentiment : 71\n",
    "Sentiment  precision: 0.0591\n",
    "Sentiment  recall: 0.3142\n",
    "Sentiment  F: 0.0995\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Decoding on CN data Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoding completed\n"
     ]
    }
   ],
   "source": [
    "emission_params = train('CN/train')\n",
    "decode('CN/dev.in',emission_params,'CN/dev.p2.out')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    ">python3 evalResult.py CN/dev.out CN/dev.p2.out\n",
    "\n",
    "#Entity in gold data: 362\n",
    "#Entity in prediction: 3318\n",
    "\n",
    "#Correct Entity : 183\n",
    "Entity  precision: 0.0552\n",
    "Entity  recall: 0.5055\n",
    "Entity  F: 0.0995\n",
    "\n",
    "#Correct Sentiment : 57\n",
    "Sentiment  precision: 0.0172\n",
    "Sentiment  recall: 0.1575\n",
    "Sentiment  F: 0.0310\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Decoding on FR data Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoding completed\n"
     ]
    }
   ],
   "source": [
    "emission_params = train('FR/train')\n",
    "decode('FR/dev.in',emission_params,'FR/dev.p2.out')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    ">python3 evalResult.py FR/dev.out FR/dev.p2.out\n",
    "\n",
    "#Entity in gold data: 223\n",
    "#Entity in prediction: 1149\n",
    "\n",
    "#Correct Entity : 182\n",
    "Entity  precision: 0.1584\n",
    "Entity  recall: 0.8161\n",
    "Entity  F: 0.2653\n",
    "\n",
    "#Correct Sentiment : 68\n",
    "Sentiment  precision: 0.0592\n",
    "Sentiment  recall: 0.3049\n",
    "Sentiment  F: 0.0991\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Decoding on SG data Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoding completed\n"
     ]
    }
   ],
   "source": [
    "emission_params = train('SG/train')\n",
    "decode('SG/dev.in',emission_params,'SG/dev.p2.out')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    ">python3 evalResult.py SG/dev.out SG/dev.p2.out\n",
    "\n",
    "#Entity in gold data: 1382\n",
    "#Entity in prediction: 6599\n",
    "\n",
    "#Correct Entity : 794\n",
    "Entity  precision: 0.1203\n",
    "Entity  recall: 0.5745\n",
    "Entity  F: 0.1990\n",
    "\n",
    "#Correct Sentiment : 315\n",
    "Sentiment  precision: 0.0477\n",
    "Sentiment  recall: 0.2279\n",
    "Sentiment  F: 0.0789\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "#Entity in gold data: 1382\r\n",
      "#Entity in prediction: 6599\r\n",
      "\r\n",
      "#Correct Entity : 794\r\n",
      "Entity  precision: 0.1203\r\n",
      "Entity  recall: 0.5745\r\n",
      "Entity  F: 0.1990\r\n",
      "\r\n",
      "#Correct Sentiment : 315\r\n",
      "Sentiment  precision: 0.0477\r\n",
      "Sentiment  recall: 0.2279\r\n",
      "Sentiment  F: 0.0789\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "p = subprocess.Popen(['python3','evalResult.py','SG/dev.out','SG/dev.p2.out'], stdout=subprocess.PIPE)\n",
    "print p.communicate()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
